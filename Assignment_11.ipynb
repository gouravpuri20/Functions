{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Function\n",
        "            \n",
        "         Logistic Regression\n",
        "\n",
        "Question 1: What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?\n",
        "\n",
        "Ans Logistic Regression and Linear Regression are both statistical models, but they’re used for different types of prediction problems and work in different ways.\n",
        "\n",
        "1. Logistic Regression\n",
        "\n",
        "Purpose: Used for classification problems (predicting categories, e.g., Yes/No, 0/1, Spam/Not Spam).\n",
        "\n",
        "Output: Predicts probabilities between 0 and 1, then classifies them into categories using a threshold (e.g., 0.5).\n",
        "Mathematics:\n",
        "\n",
        "Instead of predicting the value directly, it uses the logit function (sigmoid) to transform the linear output:\n",
        "\n",
        "p = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1x_1 + \\dots + \\beta_nx_n)}}\n",
        "\n",
        "2. Linear Regression\n",
        "\n",
        "Purpose: Used for regression problems (predicting continuous numerical values, e.g., salary, temperature, house price).\n",
        "\n",
        "Output: Predicts a continuous value that can be any real number (positive or negative).\n",
        "\n",
        "Mathematics:\n",
        "\n",
        "Directly predicts using a linear equation:\n",
        "\n",
        "y = \\beta_0 + \\beta_1x_1 + \\dots + \\beta_nx_n\n",
        "\n",
        "Question 2: Explain the role of the Sigmoid function in Logistic Regression.\n",
        "\n",
        "Ans In Logistic Regression, the sigmoid function plays a crucial role in transforming the output of a linear model into a probability score between 0 and 1. This transformation is essential for binary classification problems, where the goal is to predict the probability of an instance belonging to a particular class.\n",
        "\n",
        "Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "Ans Regularization in Logistic Regression is a technique used to prevent overfitting by adding a penalty term to the cost function, which discourages the model from assigning too much importance (large coefficients) to any single feature.\n",
        "\n",
        "Why Regularization is Needed\n",
        "\n",
        "In Logistic Regression, if some features have very large coefficients:\n",
        "\n",
        "The model fits the training data too closely (overfitting).\n",
        "\n",
        "It performs poorly on new/unseen data (low generalization).\n",
        "\n",
        "\n",
        "Regularization controls the complexity of the model so it focuses on truly important features.\n",
        "\n",
        "Question 4: What are some common evaluation metrics for classification models, and\n",
        "why are they important?\n",
        "\n",
        "Ans Evaluation metrics are used to measure how well a classification model performs. They are important because they help us:\n",
        "\n",
        "1. Quantify accuracy — to see how close predictions are to the actual outcomes.\n",
        "\n",
        "\n",
        "2. Choose the right model — especially when comparing multiple models.\n",
        "\n",
        "\n",
        "3. Handle class imbalance — some metrics work better when data is skewed."
      ],
      "metadata": {
        "id": "EBFxN9MVW7Zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load dataset from sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "# 2. Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# 3. Features (X) and Target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# 4. Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 5. Create Logistic Regression model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "\n",
        "# 6. Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predict on test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 8. Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cy1akXdPfGco",
        "outputId": "c800a569-e4f7-4360-d3a1-26b9c2c149e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Question 6: Write a Python program to train a Logistic Regression model using L2\n",
        "regularization (Ridge) and print the model coefficients and accuracy.\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# 2. Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# 3. Features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# 4. Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 5. Create Logistic Regression model with L2 regularization\n",
        "model = LogisticRegression(\n",
        "    penalty='l2',   # L2 regularization\n",
        "    C=1.0,          # Regularization strength (lower value = stronger regularization)\n",
        "    solver='lbfgs', # Solver that supports L2\n",
        "    max_iter=200\n",
        ")\n",
        "\n",
        "# 6. Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 7. Predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 8. Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# 9. Print coefficients and accuracy\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n",
        "print(\"\\nModel Intercept:\")\n",
        "print(model.intercept_)\n",
        "print(f\"\\nModel Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmk2upCcfiS9",
        "outputId": "c8a6df79-ce13-462d-bdec-7013231ece8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients:\n",
            "[[-0.39345607  0.96251768 -2.37512436 -0.99874594]\n",
            " [ 0.50843279 -0.25482714 -0.21301129 -0.77574766]\n",
            " [-0.11497673 -0.70769055  2.58813565  1.7744936 ]]\n",
            "\n",
            "Model Intercept:\n",
            "[  9.00884295   1.86902164 -10.87786459]\n",
            "\n",
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Question 7: Write a Python program to train a Logistic Regression model for multiclass\n",
        "classification using multi_class='ovr' and print the classification report.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# 1. Load dataset from sklearn\n",
        "iris = load_iris()\n",
        "\n",
        "# 2. Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# 3. Separate features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# 4. Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 5. Create Logistic Regression model with One-vs-Rest strategy\n",
        "model = LogisticRegression(\n",
        "    multi_class='ovr',\n",
        "    solver='lbfgs',\n",
        "    max_iter=200\n",
        ")\n",
        "\n",
        "# 6. Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 7. Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 8. Print classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=iris.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CT14IFhjgXWF",
        "outputId": "a807bf5a-9c92-409b-ffe5-f27f76dd04f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      0.89      0.94         9\n",
            "   virginica       0.92      1.00      0.96        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.96      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Question 8: Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "accuracy.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 1. Load dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# 2. Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# 3. Features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# 4. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 5. Create Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=500)\n",
        "\n",
        "# 6. Parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],       # L1 = Lasso, L2 = Ridge\n",
        "    'solver': ['liblinear']        # Supports both L1 and L2\n",
        "}\n",
        "\n",
        "# 7. Apply GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=log_reg,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,             # 5-fold cross-validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 8. Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 9. Print best parameters and validation accuracy\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 1. Load dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# 2. Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# 3. Features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# 4. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 5. Create Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=500)\n",
        "\n",
        "# 6. Parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],       # L1 = Lasso, L2 = Ridge\n",
        "    'solver': ['liblinear']        # Supports both L1 and L2\n",
        "}\n",
        "\n",
        "# 7. Apply GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=log_reg,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,             # 5-fold cross-validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 8. Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 9. Print best parameters and validation accuracy\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# 1. Load dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# 2. Convert to Pandas DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# 3. Features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# 4. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 5. Create Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=500)\n",
        "\n",
        "# 6. Parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],       # L1 = Lasso, L2 = Ridge\n",
        "    'solver': ['liblinear']        # Supports both L1 and L2\n",
        "}\n",
        "\n",
        "# 7. Apply GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=log_reg,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,             # 5-fold cross-validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 8. Fit GridSearchCV\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 9. Print best parameters and validation accuracy\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hiasZssirGK",
        "outputId": "5fdbff97-318d-4efe-c6fa-93cb431c7bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Cross-Validation Accuracy: 0.9583\n",
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Cross-Validation Accuracy: 0.9583\n",
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Cross-Validation Accuracy: 0.9583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Question 9: Write a Python program to standardize the features before training Logistic\n",
        "Regression and compare the model's accuracy with and without scaling.\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load dataset\n",
        "iris = load_iris()\n",
        "\n",
        "# 2. Convert to DataFrame\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "# 3. Features (X) and target (y)\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# 4. Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# Logistic Regression without scaling\n",
        "# -----------------------------\n",
        "model_no_scaling = LogisticRegression(max_iter=200)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model_no_scaling.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# -----------------------------\n",
        "# Logistic Regression with StandardScaler\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model_with_scaling = LogisticRegression(max_iter=200)\n",
        "model_with_scaling.fit(X_train_scaled, y_train)\n",
        "y_pred_with_scaling = model_with_scaling.predict(X_test_scaled)\n",
        "accuracy_with_scaling = accuracy_score(y_test, y_pred_with_scaling)\n",
        "\n",
        "# -----------------------------\n",
        "# Results\n",
        "# -----------------------------\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling:.4f}\")\n",
        "print(f\"Accuracy with scaling:    {accuracy_with_scaling:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zygmtfY9j1GD",
        "outputId": "7afb39c1-6b86-4068-c4e6-d7bcd08e3408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.0000\n",
            "Accuracy with scaling:    1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced\n",
        "dataset (only 5% of customers respond), describe the approach you’d take to build a\n",
        "Logistic Regression model — including data handling, feature scaling, balancing\n",
        "classes, hyperparameter tuning, and evaluating the model for this real-world business\n",
        "use case.\n",
        "\n",
        "Ans let’s walk through this step by step as if we’re actually in that e-commerce setting, where only 5% of customers respond to the campaign.\n",
        "That’s heavily imbalanced, so we can’t just train a default Logistic Regression and call it a day — we need a careful approach.\n",
        "\n",
        "1. Understand the Problem and Dataset\n",
        "\n",
        "Goal: Predict the probability that a customer will respond to a marketing campaign.\n",
        "\n",
        "Nature: Binary classification (respond vs not respond) with class imbalance (5% positive class).\n",
        "\n",
        "Business impact: False positives cost marketing spend; false negatives lose potential conversions.\n",
        "\n",
        "2. Data Handling\n",
        "\n",
        "Data cleaning:\n",
        "\n",
        "Handle missing values.\n",
        "\n",
        "Remove duplicates.\n",
        "\n",
        "Treat outliers (especially in features like purchase amount or activity counts).\n",
        "\n",
        "Feature engineering:\n",
        "\n",
        "Create features like recency, frequency, monetary value (RFM analysis).\n",
        "\n",
        "Include channel engagement data (email clicks, site visits, ad interactions).\n",
        "\n",
        "Encode categorical variables (One-Hot Encoding or Target Encoding).\n",
        "\n",
        "Train-test split:\n",
        "\n",
        "Stratified split so the 5% positive ratio is preserved in both sets.\n",
        "\n",
        "3. Feature Scaling\n",
        "\n",
        "Logistic Regression is sensitive to feature scale when regularization is applied.\n",
        "\n",
        "Apply StandardScaler (mean = 0, std = 1) to numeric variables.\n",
        "\n",
        "Fit scaler only on training data, then transform both train & test sets.\n",
        "\n",
        "4. Balancing Classes\n",
        "\n",
        "Two main options:\n",
        "\n",
        "1. Class weights\n",
        "\n",
        "In scikit-learn: LogisticRegression(class_weight='balanced')\n",
        "\n",
        "Adjusts the penalty so misclassifying the minority class costs more.\n",
        "\n",
        "2. Resampling\n",
        "\n",
        "Oversampling (e.g., SMOTE) to generate synthetic positive samples.\n",
        "\n",
        "Undersampling majority class to reduce imbalance.\n",
        "\n",
        "Sometimes combining both works best.\n",
        "\n",
        "5. Hyperparameter Tuning\n",
        "\n",
        "Key hyperparameters for Logistic Regression:\n",
        "\n",
        "C (inverse regularization strength) — tune across a log scale ([0.01, 0.1, 1, 10, 100]).\n",
        "\n",
        "penalty — test L1 and L2 regularization.\n",
        "\n",
        "solver — choose based on penalty (liblinear for L1/L2; lbfgs for L2).\n",
        "\n",
        "Use GridSearchCV or RandomizedSearchCV with stratified cross-validation.\n",
        "\n",
        "Include class_weight as a parameter to tune as well.\n",
        "\n",
        "6. Evaluation Strategy\n",
        "Do not rely on accuracy — it will be misleading due to imbalance.\n",
        "Use:\n",
        "\n",
        "Precision, Recall, and F1-score (especially recall if catching positives is important).\n",
        "\n",
        "ROC-AUC to measure ranking ability.\n",
        "\n",
        "Precision-Recall AUC — more informative for imbalanced datasets.\n",
        "\n",
        "Choose threshold carefully:\n",
        "\n",
        "Default 0.5 may not be optimal — adjust threshold to maximize business metric (e.g., maximize precision at 20% recall).\n",
        "\n",
        "7. Deployment Considerations\n",
        "\n",
        "Ensure feature scaling & preprocessing are part of a pipeline so production data is transformed the same way.\n",
        "\n",
        "Monitor:\n",
        "\n",
        "Data drift (customer behavior may change over time).\n",
        "\n",
        "Model performance over campaigns — retrain periodically."
      ],
      "metadata": {
        "id": "7BH4sgw4k5br"
      }
    }
  ]
}
